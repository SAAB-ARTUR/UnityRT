// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel BellhopMain

RaytracingAccelerationStructure g_AccelStruct;

struct PerRayData {
    float beta;
    uint ntop;
    uint nbot;
    uint ncaust;
    float delay;
    float curve;
    float xn;
    float qi;    
    float theta;
    float phi; // angle from source to target in the xz-plane
    uint contributing; // if ray 'hits' a target
    float TL; // transmission loss
    uint target; // index of the target the ray is headed towards
};

RWStructuredBuffer<PerRayData> PerRayDataBuffer;
RWStructuredBuffer<float3> RayPositionsBuffer;
RWStructuredBuffer<float3> debugBuf; // used to debug data on the gpu, fill it with values and write them on the cpu
RWStructuredBuffer<PerRayData> ContributingRayData;
StructuredBuffer<float2> ContributingAnglesData;
StructuredBuffer<float2> FreqsAndDampData;
StructuredBuffer<float> thetaData;
StructuredBuffer<float3> NormalBuffer; // contains normals of the triangles in the bottom. For reflections with RTAS. 

RWStructuredBuffer<PerRayData> HovemEigenRays;

struct Target {
    float xpos;
    float ypos;
    float zpos;
    float phi;
};

StructuredBuffer<Target> targetBuffer;
StructuredBuffer<uint> rayTargets;

float4x4 _SourceCameraToWorld;
float4x4 _CameraInverseProjection;

uint _MAXSTEPS;
float deltas;
uint _MAXBOTTOMHITS;
uint _MAXSURFACEHITS;

static const float PI = 3.14159265f;

// boundaries of the volume
float maxdepth;
float xmin;
float xmax;
float zmin;
float zmax;

float theta;
uint ntheta;
float3 srcDirection;
float3 srcPosition;
float dtheta;

uint freqsdamps;

struct SSP_Data 
{
    float depth;
    float velocity;
    float derivative1;
    float derivative2;
};

StructuredBuffer<SSP_Data> _SSPBuffer;
#include "BSSP.cginc"

//-------------------------------------
//- RAY

struct Ray
{
    float3 origin;
    float3 direction;
    float3 energy;
    uint nrOfInteractions;
};

#include "BTrace.cginc"
#include "RayCreation.cginc"

//-------------------------------------
//- RAYHIT

struct RayHit
{
    float3 position;
    float distance;
    float3 normal;    
    bool sendNewRay;
};

RayHit CreateRayHit()
{
    RayHit hit;
    hit.position = float3(0.0f, 0.0f, 0.0f);
    hit.distance = 1.#INF;
    hit.normal = float3(0.0f, 0.0f, 0.0f);    
    hit.sendNewRay = false;
    return hit;
}



[numthreads(1,8,1)]
void BellhopMain(uint3 id : SV_DispatchThreadID)
{
    float2 angles = CreateCylindricalRay(id);

    SSP soundSpeedProfile;
    soundSpeedProfile.type = 0;   
    
    float theta = angles.x;
    float phi = angles.y;   

    float2 xs = { 0.0,  mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).y };

    float xdiff = targetBuffer[id.x].xpos - mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).x;
    float zdiff = targetBuffer[id.x].zpos - mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).z;    

    float2 xr = { sqrt((pow(xdiff, 2.0) + pow(zdiff, 2.0))), targetBuffer[id.x].ypos };    

    PerRayData prd;    
    
    uint offset = (id.y + id.x * ntheta) * _MAXSTEPS;
    btrace(soundSpeedProfile, theta, dtheta, xs, xr, maxdepth, deltas, _MAXSURFACEHITS, _MAXBOTTOMHITS, offset, phi, prd, id);
    
    PerRayDataBuffer[id.y + id.x * ntheta] = prd;
}

#include "BTraceContributing.cginc"
#pragma kernel BellhopTraceContributingRays
[numthreads(1, 1, 1)]
void BellhopTraceContributingRays(uint3 id : SV_DispatchThreadID)
{
    // id is 1D, id.y is the only thing needed
    SSP soundSpeedProfile;
    soundSpeedProfile.type = 0;    

    float theta = ContributingAnglesData[id.y].x;
    float phi = ContributingAnglesData[id.y].y;    
    float2 xs = { 0.0,  mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).y };    

    float xdiff = targetBuffer[rayTargets[id.x]].xpos - mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).x;
    float zdiff = targetBuffer[rayTargets[id.x]].zpos - mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).z;

    float2 xr = { sqrt((pow(xdiff, 2.0) + pow(zdiff, 2.0))), targetBuffer[rayTargets[id.x]].ypos };

    PerRayData prd;    
    
    btrace_contributing(soundSpeedProfile, theta, dtheta, xs, xr, maxdepth, deltas, _MAXSURFACEHITS, _MAXBOTTOMHITS, phi, prd);

    ContributingRayData[id.y] = prd;
}

#include "HovemTrace.cginc"
#pragma kernel HovemMain
[numthreads(1, 8, 1)]
void HovemMain(uint3 id : SV_DispatchThreadID) 
{
    float2 angles = CreateCylindricalRay(id);

    SSP soundSpeedProfile;
    soundSpeedProfile.type = 0;

    float theta = angles.x;
    float phi = angles.y;

    //theta = thetaData[id.y];
    //phi = 0;    
    float2 xs = { 0.0,  mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).y };

    float xdiff = targetBuffer[id.x].xpos - mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).x;
    float zdiff = targetBuffer[id.x].zpos - mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).z;

    float2 xr = { sqrt((pow(xdiff, 2.0) + pow(zdiff, 2.0))), targetBuffer[id.x].ypos };

    PerRayData prd;    

    uint offset = (id.y + id.x * ntheta) * _MAXSTEPS; // each ray gets _MAXSTEPS nr of steps to reach the target    
    HovemTrace(soundSpeedProfile, theta, xs, xr, maxdepth, _MAXSURFACEHITS, _MAXBOTTOMHITS, offset, phi, prd, id);
    
    PerRayDataBuffer[id.y + id.x * ntheta] = prd;
}

#include "HovemTraceContributing.cginc"
#pragma kernel HovemTraceContributingRays
[numthreads(1, 1, 1)]
void HovemTraceContributingRays(uint3 id : SV_DispatchThreadID) 
{
    // Buffer HovemEigenRays contains N rays, this function will be called and create N/2 threads, rays are paired where ray 1 and 2 are paired to create an eigenray. Rays 3 and 4 are another pair.
    // Each thread will trace an eigenray and its data will replace either index i or i-1 in the buffer where i starts at 1
    // both rays in the pair (more specifically the eigenray and the other ray, the on that isn't replaced, are used to calculate transmission loss)

    SSP soundSpeedProfile;
    soundSpeedProfile.type = 0;

    uint rayIdx = 1 + (2 * id.y);    
    
    float theta = ContributingAnglesData[id.y].x;

    float phi = ContributingAnglesData[id.y].y;

    float2 xs = { 0.0,  mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).y };

    float xdiff = targetBuffer[id.x].xpos - mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).x;
    float zdiff = targetBuffer[id.x].zpos - mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).z;

    float2 xr = { sqrt((pow(xdiff, 2.0) + pow(zdiff, 2.0))), targetBuffer[id.x].ypos };    
    PerRayData prd;    
    HovemTraceContributing(soundSpeedProfile, theta, xs, xr, maxdepth, _MAXSURFACEHITS, _MAXBOTTOMHITS, phi, prd);

    // fill buffer
    uint eigIdx = 0;
    uint idx2 = 0; // index of the other ray, going to be used to clear buffer on those positions    
    if (prd.xn * ContributingRayData[rayIdx].xn > 0) {
        ContributingRayData[rayIdx] = prd;
        eigIdx = rayIdx;
        idx2 = rayIdx - 1;
    }
    else {
        ContributingRayData[rayIdx - 1] = prd;
        eigIdx = rayIdx - 1;
        idx2 = rayIdx;
    }

    // calculate transmission loss for the eigenray pairs

    float xn1 = ContributingRayData[rayIdx - 1].xn;
    float xn2 = ContributingRayData[rayIdx].xn;
    float w1 = xn2 / (xn2 - xn1);
    float w2 = 1 - w1;

    float _theta = w1 * ContributingRayData[rayIdx - 1].theta + w2 * ContributingRayData[rayIdx].theta;
    float curve = w1 * ContributingRayData[rayIdx - 1].curve + w2 * ContributingRayData[rayIdx].curve;
    float delay = w1 * ContributingRayData[rayIdx - 1].delay + w2 * ContributingRayData[rayIdx].delay;

    float ntop = ContributingRayData[rayIdx].ntop;
    float nbot = ContributingRayData[rayIdx].nbot;

    // sound speed: source, receiver
    float cs = ssp(xs.y, soundSpeedProfile, 0).c;
    float cr = ssp(xr.y, soundSpeedProfile, 0).c;

    //bottom conditions
    float c1 = ssp(maxdepth, soundSpeedProfile, 0).c;
    float c2 = 1600;
    float rho1 = 1000;
    float rho2 = 1000 * 1.8;
    // bottom reflection loss, Urick, section 5.8
    float Rbot = 1;

    float cos1 = c1 * cos(_theta) / cs;
    float cos2 = c2 * cos(_theta) / cs;
    if (cos1 <= 1 && cos2 <= 1) {
        float Y1 = sqrt(1 - cos1 * cos1) / rho1 / c1;
        float Y2 = sqrt(1 - cos2 * cos2) / rho2 / c2;
        Rbot = (Y1 - Y2) / (Y1 + Y2);
    }

    // geometrical spreading loss
    float Area_s = 2 * PI * cos(_theta) * abs(ContributingRayData[rayIdx].theta - ContributingRayData[rayIdx - 1].theta);
    float Area_r = 2 * PI * xr.x * abs(xn2 - xn1);
    float Amp0 = sqrt(Area_s / Area_r);    

    // caustic phase shift
    float ncaust = 0;
    if (xn1 < xn2 && ntop % 2 == 0) {
        ncaust = 1;
    }

    // RMS amplitude
    float Arms = 0;

    // loop over frequencies
    for (uint i = 0; i < freqsdamps; i++) {
        float npi = ntop + ncaust / 2;
        while (npi > 1) {
            npi -= 2;
        }

        float phase = npi * PI; // TODO: this should be a buffer containing phases for each frequency of the signal
        float Amp = Amp0 * pow(Rbot, nbot) * exp(-FreqsAndDampData[i].y * curve); // this should also be a buffer for the amplitudes of each frequency of the signal
        // RMS amplitude
        Arms += pow(Amp, 2);
        
    }

    // transmission loss
    float Is = 1 / rho1 / cs;
    float Ir = (Arms / freqsdamps) / rho1 / cr;
    float TL = 10 * log10(Is / Ir);
    
    ContributingRayData[eigIdx].TL = TL;
    ContributingRayData[eigIdx].ncaust = ncaust;

    PerRayData emptyRay;
    emptyRay.theta = 0;
    emptyRay.phi = 0;
    emptyRay.delay = 0;
    emptyRay.curve = 0;
    emptyRay.ntop = 0;
    emptyRay.nbot = 0;
    emptyRay.xn = 0;
    emptyRay.target = 0;
    emptyRay.TL = 0;
    emptyRay.ncaust = 0;
    emptyRay.beta = 0;
    emptyRay.qi = 0;
    emptyRay.contributing = 0;
    ContributingRayData[idx2] = emptyRay;
}

//#include "HitHandler.cginc"
#include "UnityRayQuery.cginc"
#pragma require inlineraytracing
#pragma kernel HovemWithRTAS
[numthreads(1, 8, 1)]
void HovemWithRTAS(uint3 id : SV_DispatchThreadID)
{
    SSP soundSpeedProfile;
    soundSpeedProfile.type = 0;

    // create the ray 
    float2 angles = CreateCylindricalRay(id);
    float theta = angles.x;
    float phi = angles.y;
    
    float2 xs = { 0.0,  mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).y };

    float xdiff = targetBuffer[id.x].xpos - mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).x;
    float zdiff = targetBuffer[id.x].zpos - mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).z;

    float2 xr = { sqrt((pow(xdiff, 2.0) + pow(zdiff, 2.0))), targetBuffer[id.x].ypos };

    uint offset = (id.y + id.x * ntheta) * _MAXSTEPS; // each ray gets _MAXSTEPS nr of steps to reach the target
    
    RayPositionsBuffer[0 + offset] = toCartesian(phi, xs);

    // --- initial layer traversal for the ray ---    

    // find current layer
    uint ilay = 0;
    while (_SSPBuffer[ilay].depth > xs.y) {
        ilay++;
    }

    // inital conditions
    float c = _SSPBuffer[ilay].velocity;
    float r = xs.x;
    float z = xs.y;
    float ksi = cos(theta) / c;
    float tz = -sin(theta);    
    float tau = 0;
    float len = 0;
    uint ntop = 0;
    uint nbot = 0;
    uint maxtop = _MAXSURFACEHITS;
    uint maxbot = _MAXBOTTOMHITS;

    float c0, r0, z0, tz0, tau0, len0, ilay0, dz;
    RayHit hit = CreateRayHit(); // empty hit 'struct/object'
    hit.sendNewRay = true;
    hit.position = srcPosition;

    RayPositionsBuffer[0 + offset] = srcPosition; // save the origin of the ray
    uint istep = 1;    
    float cz;
    while (hit.sendNewRay) 
    {
        // save data from previous step
        c0 = c;
        r0 = r;
        z0 = z;
        tz0 = tz;
        tau0 = tau;
        len0 = len;
        ilay0 = ilay;
        dz = 0;

        // take a step
        if (tz == 0) {
            // horizontal step
            r = xr.x;
            tau = tau0 + (r - r0) / c;
            len = len0 + (r - r0);
        }
        else {
            // next layer
            
            if (tz < 0) {
                cz = _SSPBuffer[ilay].derivative1;
                ilay = ilay + 1;
            }
            else {
                ilay = ilay - 1;
                cz = _SSPBuffer[ilay].derivative1;
            }

            // curvature
            float kappa = cz * ksi;

            // sound speed
            c = _SSPBuffer[ilay].velocity;
            float tr = c * ksi;
            
            if (tr < 1) {
                // continue in this direction
                tz = sign(tz) * sqrt(1 - tr * tr);
                z = _SSPBuffer[ilay].depth;
            }
            else {
                // U-turn
                c = c0;
                tz = -tz;
                ilay = ilay0;
                dz = (1 / ksi - c) / cz;
            }

            // integrate r, tau and len
            if (kappa != 0) {
                // arc
                r = r0 + (tz0 - tz) / kappa;
                tau = tau0 + abs(log(c / c0 * (1 + tz0) / (1 + tz)) / cz);
                float ds = sqrt(pow(r - r0, 2) + pow(z - z0, 2));
                len = len0 + ds * (1 + pow(kappa * ds, 2) / 24);
            }
            else {
                // line segment
                float ds = (z - z0) / tz;
                r = r0 + tr * ds;
                tau = tau0 + ds / c;
                len = len0 + ds;
            }
        }
        // --- layer traversal done ---     

        RayPositionsBuffer[istep + offset] = toCartesian(phi, float2(r, z)); // save the result of the step in the position buffer        

        // step taken, create ray starting from the previous position in the direction of the step's final position
        float deltar = r - r0;
        float deltaz = z - z0;
        float xstep = deltar * cos(phi);
        float zstep = deltar * sin(phi);

        float3 direction = float3(xstep, deltaz, zstep);
        direction = normalize(direction);        

        RayDesc ray; // description of the ray to be used in tracerayinline
        ray.Origin = toCartesian(phi, float2(r0, z0)); // send the ray from the previous position
        ray.Direction = direction;
        ray.TMin = 0;
        ray.TMax = 1e20f;

        const uint rayFlags = RAY_FLAG_NONE;
        UnityRayQuery<rayFlags> rayQuery;

        rayQuery.TraceRayInline(g_AccelStruct, rayFlags, 0xff, ray); // send the ray
        rayQuery.Proceed();        
        
        if (rayQuery.CommittedStatus() == COMMITTED_TRIANGLE_HIT) { // if ray has hit someting in the acceleration structure that is made of triangles
            hit.position = toCartesian(phi, float2(r0, z0)) + (ray.Direction * rayQuery.CommittedRayT());
            hit.distance = rayQuery.CommittedRayT();            
            
            if (hit.position.y < maxdepth)
            {
                hit.position.y = maxdepth;
            }
            
            if (hit.position.y > 0)
            {
                hit.position.y = 0;
            }
            
            // ray interactions with surface and bottom are the interesting cases
            if (rayQuery.CommittedInstanceID() == 1) { // surface hit, change depth direction and take new step                
                if(z >= 0) {                    
                    RayPositionsBuffer[istep + offset] = float3(hit.position.x, 0, hit.position.z); // overwrite the data stored in the position buffer with the position of the hit
                    tz = -tz;
                    ntop++;
                    z -= 0.0005; // move away from the surface slightly                    
                }        
            }
            else if (rayQuery.CommittedInstanceID() == 2) { // bottom hit, change depth direction and take new step                        
                if ((z <= hit.position.y && ray.Direction.y < 0) || (z >= hit.position.y && ray.Direction.y > 0)) // if ray hit the bottom before the end of the step
                {   
                    RayPositionsBuffer[istep + offset] = hit.position; // overwrite the data stored in the position buffer with the position of the hit
                    
                    float3 normal = NormalBuffer[rayQuery.CommittedPrimitiveIndex()].xyz; // normal of the triangle that the ray hit                    
                    float2 reflection = reflect(direction.xy, normal.xy);
                    reflection = normalize(reflection);
                    
                    c = c0 + cz * (hit.position.y - z0); // estimate the sound velocity at the depth that the ray hit the bottom

                    ilay = ilay0;
                    tz = reflection.y;
                    ksi = reflection.x / c;
                    nbot++;

                    //r = hit.position.x; // den här blir troligtvis negativ eftersom hit.position har globala koordinater och r har relativa koordninater

                    float eps = 0.001; 
                    r = abs(hit.position.x - srcPosition.x) + eps * normal.x;   // Leave the plane. 
                    z = hit.position.y + eps * normal.y;                    
                }                
            }
        }               
        
        hit.sendNewRay = (ntop <= maxtop && nbot <= maxbot && istep < _MAXSTEPS && r < (xmax - xmin) && z > maxdepth && z < 0); //continue to send a ray as long as it's in bounds and has not hit the bottom or surface too many times
        
        istep++;
    }

    // easy solution for buffer problem, positions that should be empty sometimes gets filled with weird values, therefore we force an invalid float3 (positve y-coord is not possible) into the buffer that the cpu can look for
    for (uint i = istep; i < _MAXSTEPS; i++) {
        RayPositionsBuffer[i + offset] = float3(0, 10, 0);
        debugBuf[i + offset] = float3(123, 456, 789);
    }    
}


float3 toCartesian2(float phi, float2 step)
{
    float radius = step.x;
    float deltadepth = step.y;

    return float3(radius * cos(phi), deltadepth, radius * sin(phi));
}

#pragma kernel HovemWithRTAS3D
[numthreads(1, 8, 1)]
void HovemWithRTAS3D(uint3 id : SV_DispatchThreadID)
{
    SSP soundSpeedProfile;
    soundSpeedProfile.type = 0;

    // create the ray 
    float2 angles = CreateCylindricalRay(id);
    float theta = angles.x;
    float phi = angles.y;

    float3 pos = srcPosition;

    float2 xs = { 0.0,  mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).y };

    float xdiff = targetBuffer[id.x].xpos - mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).x;
    float zdiff = targetBuffer[id.x].zpos - mul(_SourceCameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).z;

    float2 xr = { sqrt((pow(xdiff, 2.0) + pow(zdiff, 2.0))), targetBuffer[id.x].ypos };

    uint offset = (id.y + id.x * ntheta) * _MAXSTEPS; // each ray gets _MAXSTEPS nr of steps to reach the target

    RayPositionsBuffer[0 + offset] = srcPosition;

    // --- initial layer traversal for the ray ---    

    // find current layer
    uint ilay = 0;
    while (_SSPBuffer[ilay].depth > xs.y) {
        ilay++;
    }

    // inital conditions
    float c = _SSPBuffer[ilay].velocity;
    float r = 0; // r is the length of the step taken
    float depth = xs.y;
    float ksi = cos(theta) / c;
    float tdepth = -sin(theta);
    float tau = 0;
    float len = 0;
    uint ntop = 0;
    uint nbot = 0;
    uint maxtop = _MAXSURFACEHITS;
    uint maxbot = _MAXBOTTOMHITS;

    float c0, depth0, tdepth0, tau0, len0, ilay0, phi0;
    float3 pos0;
    RayHit hit = CreateRayHit(); // empty hit 'struct/object'
    hit.sendNewRay = true;
    float3 direction;
    RayPositionsBuffer[0 + offset] = srcPosition; // save the origin of the ray
    uint istep = 1;    
    while (hit.sendNewRay)
    {
        r = 0;
        // save data from previous step
        c0 = c;        
        depth0 = depth;
        tdepth0 = tdepth;
        tau0 = tau;
        len0 = len;
        ilay0 = ilay;
        phi0 = phi;
        pos0 = pos;
        float cz;        

        // take a step
        if (tdepth == 0) {
            // horizontal step
            //r = xr.x;
            
            direction = float3(cos(phi0), 0, sin(phi0));
        }
        else {
            // next layer
            
            if (tdepth < 0) {
                cz = _SSPBuffer[ilay].derivative1;
                ilay = ilay + 1;
            }
            else {
                ilay = ilay - 1;
                cz = _SSPBuffer[ilay].derivative1;
            }

            // curvature
            float kappa = cz * ksi;

            // sound speed
            c = _SSPBuffer[ilay].velocity;
            float tr = c * ksi;

            if (tr < 1) {
                // continue in this direction
                tdepth = sign(tdepth) * sqrt(1 - tr * tr);
                depth = _SSPBuffer[ilay].depth;
            }
            else {
                // U-turn
                c = c0;
                tdepth = -tdepth;
                ilay = ilay0;                
            }

            // integrate r, tau and len
            if (kappa != 0) {
                // arc
                r = (tdepth0 - tdepth) / kappa;                
            }
            else {
                // line segment
                float ds = (depth - depth0) / tdepth;
                r = tr * ds;
            }
            // step taken, create ray starting from the previous position in the direction of the step's final position
            float deltar = abs(r);
            float deltadepth = depth - depth0;
            float xstep = deltar * cos(phi);
            float zstep = deltar * sin(phi);
            direction = float3(xstep, deltadepth, zstep);            
        }
        // --- layer traversal done ---            

        RayPositionsBuffer[istep + offset] = pos0 + toCartesian2(phi, float2(r, depth-depth0)); // save the result of the step in the position buffer

        direction = normalize(direction);

        RayDesc ray; // description of the ray to be used in tracerayinline
        ray.Origin = pos0; // send the ray from the previous position
        ray.Direction = direction;
        ray.TMin = 0;
        ray.TMax = 1e20f;

        const uint rayFlags = RAY_FLAG_NONE;
        UnityRayQuery<rayFlags> rayQuery;

        rayQuery.TraceRayInline(g_AccelStruct, rayFlags, 0xff, ray); // send the ray
        rayQuery.Proceed();

        if (rayQuery.CommittedStatus() == COMMITTED_TRIANGLE_HIT) { // if ray has hit someting in the acceleration structure that is made of triangles
            hit.position = pos0 + (ray.Direction * rayQuery.CommittedRayT());
            hit.distance = rayQuery.CommittedRayT();            
            
            if (hit.position.y < maxdepth)
            {
                hit.position.y = maxdepth;
            }
            
            if (hit.position.y > 0)
            {
                hit.position.y = 0;
            }
            
            // ray interactions with surface and bottom are the interesting cases
            if (rayQuery.CommittedInstanceID() == 1) { // surface hit, change depth direction and take new step                
                if (depth >= 0) { // if the step reached the surface                    
                    RayPositionsBuffer[istep + offset] = float3(hit.position.x, 0, hit.position.z); // overwrite the data stored in the position buffer with the position of the hit
                    tdepth = -tdepth;
                    depth -= 0.0005; // move away from the surface slightly
                    ntop++;
                }
            }
            else if (rayQuery.CommittedInstanceID() == 2) { // bottom hit, change depth direction and take new step                
                if ( (depth <= hit.position.y && ray.Direction.y < 0) || (depth >= hit.position.y && ray.Direction.y > 0) ) // if ray hit the bottom before the end of the step
                {
                    float3 normal = NormalBuffer[rayQuery.CommittedPrimitiveIndex()].xyz; // normal of the triangle that the ray hit                    
                    float3 reflection = reflect(direction.xyz, normal.xyz);
                    reflection = normalize(reflection);                    

                    float radial = length(reflection.xz);
                    
                    c = c0 + cz * (hit.position.y - pos0.y); // estimate the sound velocity at the depth that the ray hit the bottom

                    ilay = ilay0;
                    tdepth = reflection.y;
                    ksi = radial / c;
                    nbot++;

                    phi = atan2(reflection.z, reflection.x);
                    
                    float eps = 0.001;                    
                    depth = hit.position.y + eps * normal.y; // move away from the bottom slightly                    
                    
                    RayPositionsBuffer[istep + offset] = hit.position + eps * normal; // overwrite the data stored in the position buffer with the position of the hit
                }
            }
        }
        
        pos = RayPositionsBuffer[istep + offset];

        istep++;        
        
        hit.sendNewRay = (ntop <= maxtop && nbot <= maxbot && istep < _MAXSTEPS && pos.y >= maxdepth && pos.y <= 0 && pos.x <= xmax && pos.x >= xmin && pos.z <= zmax && pos.z >= zmin);
    }

    // easy solution for buffer problem, positions that should be empty sometimes gets filled with weird values, therefore we force an invalid float3 (positve y-coord is not possible) into the buffer that the cpu can look for
    for (uint i = istep; i < _MAXSTEPS; i++) {
        RayPositionsBuffer[i + offset] = float3(0, 10, 0);
        debugBuf[i + offset] = float3(123, 456, 789);
    }
}


